{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook: Inference - Tomato Disease Prediction\n",
    "\n",
    "**Project:** DeepSpec-Tomato: A Dual-Stage CAE-CNN Diagnostic Framework  \n",
    "**Author:** Muhammad Ali Tahir  \n",
    "**Date:** 2025  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã Notebook Purpose\n",
    "\n",
    "This notebook provides a **production-ready inference pipeline** for predicting tomato leaf diseases using the trained CAE-CNN model.\n",
    "\n",
    "### Features:\n",
    "- Single image prediction\n",
    "- Batch prediction (folder of images)\n",
    "- Confidence scores with visualization\n",
    "- Top-K predictions\n",
    "- Exportable results (CSV/JSON)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Union, List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Notebook executed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROJECT PATHS\n",
    "# =============================================================================\n",
    "\n",
    "class ProjectPaths:\n",
    "    \"\"\"Centralized path management.\"\"\"\n",
    "    \n",
    "    ROOT = Path(\"/home/maliciit/ml-projects/python-projects/plant-village-cae\")\n",
    "    DATA_PROCESSED = ROOT / \"data\" / \"processed\"\n",
    "    MODELS = ROOT / \"models\"\n",
    "    OUTPUTS = ROOT / \"outputs\"\n",
    "    CONFIG = ROOT / \"config\"\n",
    "\n",
    "PATHS = ProjectPaths()\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODEL ARCHITECTURE (Must match training)\n",
    "# =============================================================================\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder from CAE.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_channels=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, latent_channels, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(latent_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class TomatoClassifier(nn.Module):\n",
    "    \"\"\"Classification model.\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder, num_classes, hidden_dim=512, dropout=0.4):\n",
    "        super(TomatoClassifier, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 16 * 16, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.classifier(features)\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"Return softmax probabilities.\"\"\"\n",
    "        logits = self.forward(x)\n",
    "        return F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD TRAINED MODEL\n",
    "# =============================================================================\n",
    "\n",
    "def load_model(model_path: Path, device: torch.device) -> Tuple[TomatoClassifier, Dict]:\n",
    "    \"\"\"\n",
    "    Load trained model and its configuration.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model (.pth)\n",
    "        device: Device to load model on\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (model, config_dict)\n",
    "    \"\"\"\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    # Extract configuration\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    class_names = checkpoint['class_names']\n",
    "    image_size = checkpoint['image_size']\n",
    "    norm_mean = checkpoint['normalization']['mean']\n",
    "    norm_std = checkpoint['normalization']['std']\n",
    "    \n",
    "    # Build model\n",
    "    encoder = Encoder(latent_channels=128)\n",
    "    model = TomatoClassifier(\n",
    "        encoder=encoder,\n",
    "        num_classes=num_classes,\n",
    "        hidden_dim=512,\n",
    "        dropout=0.4\n",
    "    )\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    config = {\n",
    "        'num_classes': num_classes,\n",
    "        'class_names': class_names,\n",
    "        'class_names_raw': checkpoint.get('class_names_raw', class_names),\n",
    "        'image_size': image_size,\n",
    "        'norm_mean': norm_mean,\n",
    "        'norm_std': norm_std,\n",
    "        'best_f1': checkpoint.get('best_f1', None),\n",
    "        'best_accuracy': checkpoint.get('best_accuracy', None)\n",
    "    }\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "# Load model\n",
    "MODEL_PATH = PATHS.MODELS / 'classifier_final.pth'\n",
    "model, model_config = load_model(MODEL_PATH, DEVICE)\n",
    "\n",
    "print(f\"‚úì Model loaded from: {MODEL_PATH}\")\n",
    "print(f\"\\n  Number of classes: {model_config['num_classes']}\")\n",
    "print(f\"  Image size: {model_config['image_size']}√ó{model_config['image_size']}\")\n",
    "print(f\"  Best F1 (training): {model_config['best_f1']:.4f}\")\n",
    "print(f\"  Best Accuracy (training): {model_config['best_accuracy']:.2%}\")\n",
    "print(f\"\\n  Classes:\")\n",
    "for i, name in enumerate(model_config['class_names']):\n",
    "    print(f\"    [{i}] {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Inference transform created\n",
      "  Normalization mean: [0.45038148760795593, 0.4661545753479004, 0.4010584056377411]\n",
      "  Normalization std: [0.17417825758457184, 0.1513632982969284, 0.19069136679172516]\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PREPROCESSING TRANSFORM\n",
    "# =============================================================================\n",
    "\n",
    "def get_inference_transform(image_size: int, mean: List[float], std: List[float]):\n",
    "    \"\"\"\n",
    "    Create preprocessing transform for inference.\n",
    "    \n",
    "    Args:\n",
    "        image_size: Target image size\n",
    "        mean: Normalization mean (from training set)\n",
    "        std: Normalization std (from training set)\n",
    "    \n",
    "    Returns:\n",
    "        torchvision.transforms.Compose\n",
    "    \"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "# Create transform\n",
    "inference_transform = get_inference_transform(\n",
    "    model_config['image_size'],\n",
    "    model_config['norm_mean'],\n",
    "    model_config['norm_std']\n",
    ")\n",
    "\n",
    "print(\"‚úì Inference transform created\")\n",
    "print(f\"  Normalization mean: {model_config['norm_mean']}\")\n",
    "print(f\"  Normalization std: {model_config['norm_std']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Predictor initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TOMATO DISEASE PREDICTOR CLASS\n",
    "# =============================================================================\n",
    "\n",
    "class TomatoDiseasePredictor:\n",
    "    \"\"\"\n",
    "    Production-ready predictor for tomato leaf disease classification.\n",
    "    \n",
    "    Usage:\n",
    "        predictor = TomatoDiseasePredictor(model, config, device)\n",
    "        result = predictor.predict('path/to/image.jpg')\n",
    "        results = predictor.predict_batch('path/to/folder')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model: nn.Module, config: Dict, device: torch.device):\n",
    "        \"\"\"\n",
    "        Initialize predictor.\n",
    "        \n",
    "        Args:\n",
    "            model: Trained PyTorch model\n",
    "            config: Model configuration dict\n",
    "            device: Device to run inference on\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.class_names = config['class_names']\n",
    "        self.num_classes = config['num_classes']\n",
    "        \n",
    "        # Create transform\n",
    "        self.transform = get_inference_transform(\n",
    "            config['image_size'],\n",
    "            config['norm_mean'],\n",
    "            config['norm_std']\n",
    "        )\n",
    "        \n",
    "        # Ensure model is in eval mode\n",
    "        self.model.eval()\n",
    "    \n",
    "    def _load_image(self, image_source: Union[str, Path, Image.Image]) -> Image.Image:\n",
    "        \"\"\"\n",
    "        Load image from various sources.\n",
    "        \n",
    "        Args:\n",
    "            image_source: Path string, Path object, or PIL Image\n",
    "        \n",
    "        Returns:\n",
    "            PIL Image in RGB mode\n",
    "        \"\"\"\n",
    "        if isinstance(image_source, Image.Image):\n",
    "            img = image_source\n",
    "        else:\n",
    "            img = Image.open(image_source)\n",
    "        \n",
    "        # Convert to RGB if necessary\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def _preprocess(self, image: Image.Image) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Preprocess image for model input.\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image\n",
    "        \n",
    "        Returns:\n",
    "            Preprocessed tensor [1, C, H, W]\n",
    "        \"\"\"\n",
    "        tensor = self.transform(image)\n",
    "        return tensor.unsqueeze(0).to(self.device)\n",
    "    \n",
    "    def predict(\n",
    "        self, \n",
    "        image_source: Union[str, Path, Image.Image],\n",
    "        top_k: int = 3,\n",
    "        threshold: float = 0.0\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Predict disease for a single image.\n",
    "        \n",
    "        Args:\n",
    "            image_source: Path to image or PIL Image\n",
    "            top_k: Number of top predictions to return\n",
    "            threshold: Minimum confidence threshold (0-1)\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with prediction results:\n",
    "            {\n",
    "                'predicted_class': str,\n",
    "                'predicted_index': int,\n",
    "                'confidence': float,\n",
    "                'top_k_predictions': [(class_name, confidence), ...],\n",
    "                'all_probabilities': {class_name: prob, ...},\n",
    "                'is_confident': bool,\n",
    "                'image_path': str\n",
    "            }\n",
    "        \"\"\"\n",
    "        # Load and preprocess\n",
    "        image = self._load_image(image_source)\n",
    "        input_tensor = self._preprocess(image)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            probabilities = self.model.predict_proba(input_tensor)\n",
    "        \n",
    "        # Process results\n",
    "        probs = probabilities.cpu().numpy()[0]\n",
    "        \n",
    "        # Get top-k predictions\n",
    "        top_k_indices = np.argsort(probs)[::-1][:top_k]\n",
    "        top_k_predictions = [\n",
    "            (self.class_names[idx], float(probs[idx]))\n",
    "            for idx in top_k_indices\n",
    "        ]\n",
    "        \n",
    "        # Best prediction\n",
    "        predicted_idx = int(top_k_indices[0])\n",
    "        predicted_class = self.class_names[predicted_idx]\n",
    "        confidence = float(probs[predicted_idx])\n",
    "        \n",
    "        # All probabilities\n",
    "        all_probs = {name: float(probs[i]) for i, name in enumerate(self.class_names)}\n",
    "        \n",
    "        # Image path (if applicable)\n",
    "        img_path = str(image_source) if isinstance(image_source, (str, Path)) else \"PIL Image\"\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': predicted_class,\n",
    "            'predicted_index': predicted_idx,\n",
    "            'confidence': confidence,\n",
    "            'top_k_predictions': top_k_predictions,\n",
    "            'all_probabilities': all_probs,\n",
    "            'is_confident': confidence >= threshold,\n",
    "            'image_path': img_path\n",
    "        }\n",
    "    \n",
    "    def predict_batch(\n",
    "        self,\n",
    "        folder_path: Union[str, Path],\n",
    "        extensions: Tuple[str, ...] = ('.jpg', '.jpeg', '.png', '.bmp'),\n",
    "        top_k: int = 1,\n",
    "        threshold: float = 0.0\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Predict diseases for all images in a folder.\n",
    "        \n",
    "        Args:\n",
    "            folder_path: Path to folder containing images\n",
    "            extensions: Valid image extensions\n",
    "            top_k: Number of top predictions per image\n",
    "            threshold: Minimum confidence threshold\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with predictions for all images\n",
    "        \"\"\"\n",
    "        folder = Path(folder_path)\n",
    "        \n",
    "        if not folder.exists():\n",
    "            raise FileNotFoundError(f\"Folder not found: {folder}\")\n",
    "        \n",
    "        # Find all images\n",
    "        image_files = []\n",
    "        for ext in extensions:\n",
    "            image_files.extend(folder.glob(f'*{ext}'))\n",
    "            image_files.extend(folder.glob(f'*{ext.upper()}'))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(f\"‚ö† No images found in {folder}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        print(f\"Processing {len(image_files)} images...\")\n",
    "        \n",
    "        # Process each image\n",
    "        results = []\n",
    "        for img_path in image_files:\n",
    "            try:\n",
    "                result = self.predict(img_path, top_k=top_k, threshold=threshold)\n",
    "                results.append({\n",
    "                    'filename': img_path.name,\n",
    "                    'predicted_class': result['predicted_class'],\n",
    "                    'confidence': result['confidence'],\n",
    "                    'is_confident': result['is_confident']\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"  ‚ö† Error processing {img_path.name}: {e}\")\n",
    "                results.append({\n",
    "                    'filename': img_path.name,\n",
    "                    'predicted_class': 'ERROR',\n",
    "                    'confidence': 0.0,\n",
    "                    'is_confident': False\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def predict_with_visualization(\n",
    "        self,\n",
    "        image_source: Union[str, Path, Image.Image],\n",
    "        top_k: int = 5,\n",
    "        figsize: Tuple[int, int] = (12, 5)\n",
    "    ) -> Dict:\n",
    "        \"\"\"\n",
    "        Predict and visualize results.\n",
    "        \n",
    "        Args:\n",
    "            image_source: Path to image or PIL Image\n",
    "            top_k: Number of top predictions to show\n",
    "            figsize: Figure size\n",
    "        \n",
    "        Returns:\n",
    "            Prediction result dictionary\n",
    "        \"\"\"\n",
    "        # Get prediction\n",
    "        result = self.predict(image_source, top_k=top_k)\n",
    "        \n",
    "        # Load image for display\n",
    "        image = self._load_image(image_source)\n",
    "        \n",
    "        # Create figure\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "        \n",
    "        # Plot 1: Image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Title with prediction\n",
    "        title_color = 'green' if result['confidence'] > 0.8 else 'orange' if result['confidence'] > 0.5 else 'red'\n",
    "        axes[0].set_title(\n",
    "            f\"Prediction: {result['predicted_class']}\\n\"\n",
    "            f\"Confidence: {result['confidence']:.1%}\",\n",
    "            fontsize=12, fontweight='bold', color=title_color\n",
    "        )\n",
    "        \n",
    "        # Plot 2: Top-K probabilities\n",
    "        top_k_names = [p[0] for p in result['top_k_predictions']]\n",
    "        top_k_probs = [p[1] for p in result['top_k_predictions']]\n",
    "        \n",
    "        colors = ['#2ecc71' if i == 0 else '#3498db' for i in range(len(top_k_names))]\n",
    "        \n",
    "        bars = axes[1].barh(top_k_names[::-1], top_k_probs[::-1], color=colors[::-1])\n",
    "        axes[1].set_xlabel('Confidence', fontsize=11)\n",
    "        axes[1].set_xlim(0, 1)\n",
    "        axes[1].set_title('Top Predictions', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for bar, prob in zip(bars, top_k_probs[::-1]):\n",
    "            axes[1].text(prob + 0.02, bar.get_y() + bar.get_height()/2,\n",
    "                        f'{prob:.1%}', va='center', fontsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = TomatoDiseasePredictor(model, model_config, DEVICE)\n",
    "print(\"\\n‚úì Predictor initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXAMPLE: SINGLE IMAGE PREDICTION\n",
    "# =============================================================================\n",
    "\n",
    "# Option 1: Using a test image from the dataset\n",
    "TEST_PATH = PATHS.DATA_PROCESSED / 'test'\n",
    "\n",
    "# Get a sample image (handle multiple extensions)\n",
    "sample_class = list(TEST_PATH.iterdir())[0]  # First class folder\n",
    "\n",
    "# Find images with various extensions\n",
    "image_extensions = ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']\n",
    "sample_images = []\n",
    "for ext in image_extensions:\n",
    "    sample_images.extend(list(sample_class.glob(ext)))\n",
    "\n",
    "if not sample_images:\n",
    "    print(f\"‚ö† No images found in {sample_class}\")\n",
    "    print(f\"  Contents: {list(sample_class.iterdir())[:5]}\")\n",
    "else:\n",
    "    sample_image = sample_images[0]  # First image found\n",
    "    \n",
    "    print(f\"Sample image: {sample_image}\")\n",
    "    print(f\"True label: {sample_class.name}\\n\")\n",
    "    \n",
    "    # Predict\n",
    "    result = predictor.predict(sample_image, top_k=5)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"=\"*50)\n",
    "    print(\"PREDICTION RESULT\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Predicted class: {result['predicted_class']}\")\n",
    "    print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "    print(f\"\\nTop 5 predictions:\")\n",
    "    for i, (cls, prob) in enumerate(result['top_k_predictions'], 1):\n",
    "        print(f\"  {i}. {cls}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREDICTION WITH VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "# Predict and visualize\n",
    "result = predictor.predict_with_visualization(sample_image, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MULTIPLE SAMPLE PREDICTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_multiple_predictions(predictor, test_path, n_samples=6):\n",
    "    \"\"\"\n",
    "    Visualize predictions for multiple random samples.\n",
    "    \"\"\"\n",
    "    # Collect sample images from different classes\n",
    "    samples = []\n",
    "    class_folders = [f for f in test_path.iterdir() if f.is_dir()]\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    selected_folders = np.random.choice(class_folders, min(n_samples, len(class_folders)), replace=False)\n",
    "    \n",
    "    for class_folder in selected_folders:\n",
    "        # Find images with various extensions\n",
    "        images = []\n",
    "        for ext in ['*.jpg', '*.JPG', '*.jpeg', '*.JPEG', '*.png', '*.PNG']:\n",
    "            images.extend(list(class_folder.glob(ext)))\n",
    "        \n",
    "        if images:\n",
    "            samples.append({\n",
    "                'path': np.random.choice(images),\n",
    "                'true_label': class_folder.name.split('___')[-1].replace('_', ' ').title()\n",
    "            })\n",
    "    \n",
    "    if not samples:\n",
    "        print(\"‚ö† No samples found!\")\n",
    "        return\n",
    "    \n",
    "    # Create figure\n",
    "    n_cols = 3\n",
    "    n_rows = (len(samples) + n_cols - 1) // n_cols\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    if n_rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        # Predict\n",
    "        result = predictor.predict(sample['path'])\n",
    "        \n",
    "        # Load image\n",
    "        img = Image.open(sample['path'])\n",
    "        \n",
    "        # Display\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Check if correct (flexible matching)\n",
    "        true_clean = sample['true_label'].lower().replace(' ', '').replace('-', '')\n",
    "        pred_clean = result['predicted_class'].lower().replace(' ', '').replace('-', '')\n",
    "        is_correct = true_clean in pred_clean or pred_clean in true_clean\n",
    "        \n",
    "        color = 'green' if is_correct else 'red'\n",
    "        symbol = '‚úì' if is_correct else '‚úó'\n",
    "        \n",
    "        axes[i].set_title(\n",
    "            f\"True: {sample['true_label'][:25]}\\n\"\n",
    "            f\"Pred: {result['predicted_class'][:25]}\\n\"\n",
    "            f\"Conf: {result['confidence']:.1%} {symbol}\",\n",
    "            fontsize=10, color=color, fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    # Hide empty axes\n",
    "    for j in range(len(samples), len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.suptitle('Sample Predictions from Test Set', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig_path = PATHS.OUTPUTS / 'fig_inference_samples.png'\n",
    "    plt.savefig(fig_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"‚úì Figure saved: {fig_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_multiple_predictions(predictor, TEST_PATH, n_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BATCH PREDICTION ON A FOLDER\n",
    "# =============================================================================\n",
    "\n",
    "# Example: Predict on one class folder\n",
    "sample_folder = list(TEST_PATH.iterdir())[0]\n",
    "print(f\"Running batch prediction on: {sample_folder.name}\\n\")\n",
    "\n",
    "# Predict\n",
    "batch_results = predictor.predict_batch(sample_folder, threshold=0.8)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n‚úì Processed {len(batch_results)} images\")\n",
    "print(f\"\\nResults summary:\")\n",
    "print(batch_results.head(10))\n",
    "\n",
    "# Statistics\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"BATCH STATISTICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total images: {len(batch_results)}\")\n",
    "print(f\"Average confidence: {batch_results['confidence'].mean():.2%}\")\n",
    "print(f\"Min confidence: {batch_results['confidence'].min():.2%}\")\n",
    "print(f\"Max confidence: {batch_results['confidence'].max():.2%}\")\n",
    "print(f\"Confident predictions (‚â•80%): {batch_results['is_confident'].sum()} ({batch_results['is_confident'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Results saved to: /home/maliciit/ml-projects/python-projects/plant-village-cae/outputs/batch_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXPORT BATCH RESULTS TO CSV\n",
    "# =============================================================================\n",
    "\n",
    "# Save results\n",
    "output_csv = PATHS.OUTPUTS / 'batch_predictions.csv'\n",
    "batch_results.to_csv(output_csv, index=False)\n",
    "print(f\"‚úì Results saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Custom Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREDICT ON YOUR OWN IMAGE\n",
    "# =============================================================================\n",
    "\n",
    "# ‚ö†Ô∏è UNCOMMENT AND MODIFY THE PATH BELOW TO USE YOUR OWN IMAGE\n",
    "\n",
    "# your_image_path = \"/path/to/your/tomato_leaf_image.jpg\"\n",
    "# result = predictor.predict_with_visualization(your_image_path, top_k=5)\n",
    "\n",
    "# print(\"\\nFull prediction details:\")\n",
    "# print(json.dumps({k: v for k, v in result.items() if k != 'all_probabilities'}, indent=2))\n",
    "\n",
    "print(\"To predict on your own image:\")\n",
    "print(\"1. Upload your image to this notebook environment\")\n",
    "print(\"2. Uncomment the code above\")\n",
    "print(\"3. Update 'your_image_path' with the correct path\")\n",
    "print(\"4. Run the cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Export Predictor for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT MODEL FOR PRODUCTION USE\n",
    "# =============================================================================\n",
    "\n",
    "def export_for_production(model, config, output_dir: Path):\n",
    "    \"\"\"\n",
    "    Export model and configuration for production deployment.\n",
    "    \n",
    "    Creates:\n",
    "    - model.pth (model weights)\n",
    "    - config.json (model configuration)\n",
    "    - inference.py (standalone inference script)\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # 1. Save model weights only\n",
    "    model_path = output_dir / 'model_weights.pth'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print(f\"‚úì Model weights saved: {model_path}\")\n",
    "    \n",
    "    # 2. Save configuration\n",
    "    config_path = output_dir / 'model_config.json'\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    print(f\"‚úì Configuration saved: {config_path}\")\n",
    "    \n",
    "    # 3. Create standalone inference script\n",
    "    inference_script = '''#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Standalone inference script for Tomato Disease Classification.\n",
    "\n",
    "Usage:\n",
    "    python inference.py --image path/to/image.jpg\n",
    "    python inference.py --folder path/to/folder --output results.csv\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_channels=128):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1), nn.BatchNorm2d(32), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1), nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.Conv2d(64, latent_channels, 3, stride=2, padding=1), nn.BatchNorm2d(latent_channels), nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, x): return self.encoder(x)\n",
    "\n",
    "\n",
    "class TomatoClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*16*16, 512), nn.BatchNorm1d(512), nn.ReLU(True), nn.Dropout(0.4),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x): return self.classifier(self.encoder(x))\n",
    "\n",
    "\n",
    "def load_model(model_dir):\n",
    "    model_dir = Path(model_dir)\n",
    "    with open(model_dir / \"model_config.json\") as f:\n",
    "        config = json.load(f)\n",
    "    model = TomatoClassifier(config[\"num_classes\"])\n",
    "    model.load_state_dict(torch.load(model_dir / \"model_weights.pth\", map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    return model, config\n",
    "\n",
    "\n",
    "def predict(model, config, image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((config[\"image_size\"], config[\"image_size\"])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(config[\"norm_mean\"], config[\"norm_std\"])\n",
    "    ])\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    tensor = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        probs = F.softmax(model(tensor), dim=1)[0].numpy()\n",
    "    idx = probs.argmax()\n",
    "    return config[\"class_names\"][idx], float(probs[idx])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-dir\", default=\".\", help=\"Directory with model files\")\n",
    "    parser.add_argument(\"--image\", help=\"Single image path\")\n",
    "    parser.add_argument(\"--folder\", help=\"Folder with images\")\n",
    "    parser.add_argument(\"--output\", default=\"predictions.csv\", help=\"Output CSV for batch\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    model, config = load_model(args.model_dir)\n",
    "    \n",
    "    if args.image:\n",
    "        cls, conf = predict(model, config, args.image)\n",
    "        print(f\"Prediction: {cls} (Confidence: {conf:.1%})\")\n",
    "    elif args.folder:\n",
    "        results = []\n",
    "        for p in Path(args.folder).glob(\"*\"):\n",
    "            if p.suffix.lower() in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "                cls, conf = predict(model, config, p)\n",
    "                results.append({\"file\": p.name, \"class\": cls, \"confidence\": conf})\n",
    "        pd.DataFrame(results).to_csv(args.output, index=False)\n",
    "        print(f\"Results saved to {args.output}\")\n",
    "'''\n",
    "    \n",
    "    script_path = output_dir / 'inference.py'\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write(inference_script)\n",
    "    print(f\"‚úì Inference script saved: {script_path}\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    print(\"PRODUCTION EXPORT COMPLETE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"\\nFiles exported to: {output_dir}\")\n",
    "    print(\"\\nUsage:\")\n",
    "    print(f\"  python {script_path} --model-dir {output_dir} --image your_image.jpg\")\n",
    "    print(f\"  python {script_path} --model-dir {output_dir} --folder your_folder --output results.csv\")\n",
    "\n",
    "# Export\n",
    "export_dir = PATHS.MODELS / 'production'\n",
    "export_for_production(model, model_config, export_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Summary\n",
    "\n",
    "### ‚úÖ Inference Pipeline Features\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Single Image** | `predictor.predict(image_path)` |\n",
    "| **With Visualization** | `predictor.predict_with_visualization(image_path)` |\n",
    "| **Batch Processing** | `predictor.predict_batch(folder_path)` |\n",
    "| **Top-K Predictions** | Returns top K most likely classes |\n",
    "| **Confidence Threshold** | Filter low-confidence predictions |\n",
    "| **Export Results** | Save to CSV |\n",
    "\n",
    "### üìÅ Production Files\n",
    "\n",
    "```\n",
    "models/production/\n",
    "‚îú‚îÄ‚îÄ model_weights.pth   # Lightweight weights file\n",
    "‚îú‚îÄ‚îÄ model_config.json   # Configuration (classes, normalization)\n",
    "‚îî‚îÄ‚îÄ inference.py        # Standalone CLI script\n",
    "```\n",
    "\n",
    "### üöÄ Next Steps\n",
    "\n",
    "- Deploy with **FastAPI** or **Flask** for REST API\n",
    "- Create **Gradio** or **Streamlit** web interface\n",
    "- Convert to **ONNX** for cross-platform deployment\n",
    "- Optimize with **TorchScript** for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOTEBOOK COMPLETION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì INFERENCE NOTEBOOK COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Execution finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\nModel: {MODEL_PATH}\")\n",
    "print(f\"Production export: {export_dir}\")\n",
    "print(\"\\nReady for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
